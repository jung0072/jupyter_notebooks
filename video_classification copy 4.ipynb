{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN9f1BlmFOUi",
        "outputId": "e7acddf7-3078-407f-f02f-ab73aa5f23ed"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rE02sO-nE2gs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.0.1\n",
            "Is MPS (Metal Performance Shader) built? True\n",
            "Is MPS available? True\n",
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from timeit import default_timer as timer \n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
        "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
        "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
        "\n",
        "# Set the device      \n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5XBkhoBE2gu"
      },
      "source": [
        "# 1. Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m94KrPQzE2gv"
      },
      "outputs": [],
      "source": [
        "# For Colab\n",
        "# ucf_train_data_preprocessed_dir = \"/content/drive/My Drive/Minki_ML_Data_free_to_delete/\"\n",
        "\n",
        "ucf_train_data_preprocessed_dir = \"../resources/UCF-101/data_preprocessed/train\"\n",
        "ucf_test_data_preprocessed_dir = \"../resources/UCF-101/data_preprocessed/test\"\n",
        "batch_size = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_list = os.listdir(ucf_train_data_preprocessed_dir)\n",
        "class_list_test = os.listdir(ucf_test_data_preprocessed_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-IJ_Vh4WE2gw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class UCFDataset(Dataset):\n",
        "    def __init__(self, root_dir, frames_per_clip, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.frames_per_clip = frames_per_clip\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(file for file in os.listdir(root_dir) if file != '.DS_Store')\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum([len(files) for _, _, files in os.walk(self.root_dir)])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Calculate accumulated number of videos for each class\n",
        "        accum_video_counts = [0]\n",
        "        for class_name in self.classes:\n",
        "            class_dir = os.path.join(self.root_dir, class_name)\n",
        "            accum_video_counts.append(accum_video_counts[-1] + len(os.listdir(class_dir)))\n",
        "\n",
        "        # Determine the class index\n",
        "        class_idx = next(i for i, count in enumerate(accum_video_counts[1:]) if idx < count)\n",
        "        class_name = self.classes[class_idx]\n",
        "        class_dir = os.path.join(self.root_dir, class_name)\n",
        "        video_files = sorted(os.listdir(class_dir))\n",
        "\n",
        "        # Adjust the index based on the accumulated counts\n",
        "        adjusted_idx = idx - accum_video_counts[class_idx]\n",
        "        video_name = video_files[adjusted_idx % len(video_files)]\n",
        "        video_path = os.path.join(class_dir, video_name)\n",
        "        frame_position = (adjusted_idx % len(video_files)) % self.frames_per_clip\n",
        "        frame = torch.load(video_path)[frame_position]\n",
        "        frame = frame.permute([2, 0, 1])\n",
        "        # frame = frame.to(device)\n",
        "\n",
        "        label = class_name\n",
        "        target = torch.tensor(class_list.index(label))\n",
        "        # target = target.to(device)\n",
        "\n",
        "        if self.transform:\n",
        "            frame = self.transform(frame)\n",
        "\n",
        "        return frame, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7upTVGnjE2gx"
      },
      "outputs": [],
      "source": [
        "frames_per_clip = 5\n",
        "\n",
        "train_dataset = UCFDataset(ucf_train_data_preprocessed_dir, frames_per_clip)\n",
        "test_dataset = UCFDataset(ucf_test_data_preprocessed_dir, frames_per_clip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional import resize\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    images, labels = zip(*batch)\n",
        "\n",
        "    # Resize all images in the batch to a common size\n",
        "    images = [resize(img, (240, 320)) for img in images]\n",
        "\n",
        "    return torch.stack(images), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cg5VanrSE2gx"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, pin_memory=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, pin_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "Q1io9PXmE2gx",
        "outputId": "b4a3f6de-785d-4209-d084-8a6b2b4a765f"
      },
      "outputs": [],
      "source": [
        "# Show a batch\n",
        "skip_execution = True\n",
        "\n",
        "if not skip_execution:\n",
        "    for x, y in train_loader:\n",
        "        print(\"Shape of Batch: \", x.shape)\n",
        "\n",
        "        fig, axes = plt.subplots(7,5,figsize=(10, 10))\n",
        "\n",
        "        # Loop through the subplots and display the images\n",
        "        for ax, image, label in zip(axes.flat, x, y):\n",
        "            image = image.to(dtype=torch.int)\n",
        "            image = torch.permute(image, [1,2,0])\n",
        "            ax.imshow(image)  # You can set the colormap here\n",
        "            ax.axis('off')  # Turn off axis labels and ticks\n",
        "            ax.set_title(label, fontsize=10, pad=5)  # Set title as the label\n",
        "\n",
        "\n",
        "        # Adjust spacing between subplots for better layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Show the grid of images\n",
        "        plt.show()\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIzt6F7fE2gy"
      },
      "source": [
        "# 2. Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P6fhmWDUL8Xm"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def conv(input_channel, output_channel):\n",
        "  conv = nn.Conv2d(input_channel, output_channel, groups=1, bias=True, kernel_size=3, padding=0, stride=2)\n",
        "  m = nn.Sequential(conv, nn.ReLU())\n",
        "  return m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_net = nn.Sequential(\n",
        "    nn.Linear(128, 72),\n",
        "    nn.ReLU(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Gg_NBWTJMPQE"
      },
      "outputs": [],
      "source": [
        "cnn = nn.Sequential(\n",
        "    conv(3, 32),\n",
        "    conv(32, 64),\n",
        "    conv(64, 128),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    nn.Flatten(),\n",
        "    full_net\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fully connected layer (Filtered image to class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy_top3(y, targets):\n",
        "    accuracies = []\n",
        "    _, top_3_indices = torch.topk(y, 3)\n",
        "    for target,result in zip(targets,top_3_indices):\n",
        "        # print(\"target: \", target)\n",
        "        # print(\"top_3_indices: \", result)\n",
        "        # print(\"--------\")\n",
        "        if target in result:\n",
        "            accuracies.append(1)\n",
        "        else:\n",
        "            accuracies.append(0)\n",
        "\n",
        "    return sum(accuracies) / len(accuracies)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "akRDPDVRE2gy"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "accuracies = []\n",
        "count = 0\n",
        "num_epochs = 0\n",
        "skip_execution = True\n",
        "\n",
        "if not skip_execution:\n",
        "    for epoch in range(num_epochs): \n",
        "        for x, y in train_loader:\n",
        "            count += 1     \n",
        "            target = [class_list.index(y[i]) for i in range(len(y))]\n",
        "            target_in_array = torch.tensor([[1 if i == value else 0 for i in range(len(class_list))] for value in target], dtype=torch.float32)\n",
        "            \n",
        "            loss_function = nn.MSELoss()\n",
        "            optimizer = optim.SGD(cnn.parameters(), lr=1e-3)\n",
        "\n",
        "            res = cnn(x)\n",
        "            accuracy = accuracy_top3(res, target)\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "            loss = loss_function(res, target_in_array)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    print(\"Total epoches\", count)\n",
        "    print(\"Total acc\", len(accuracies))\n",
        "    plt.plot(accuracies)\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Top-3 Accuracy')\n",
        "    plt.title('Training Top-3 Accuracy')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check the accuracy with the testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "accuracies = []\n",
        "\n",
        "skip_execution = True\n",
        "\n",
        "if not skip_execution:\n",
        "    for x, y in test_loader:\n",
        "        target = [class_list_test.index(y[i]) for i in range(len(y))]\n",
        "        \n",
        "        res = cnn(x)\n",
        "        \n",
        "        accuracy = accuracy_top3(res, target)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    print(\"Average accuracy: \",sum(accuracies) / len(accuracies))\n",
        "\n",
        "    print(len(accuracies))\n",
        "    plt.plot(accuracies)\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Top-3 Accuracy')\n",
        "    plt.title('Training Top-3 Accuracy')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Troubleshooting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I was training a model from scratch. But the frames from the videos that I’m using to train the model are too little to train image classification. I’d better use a pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class ResNetForClassification(nn.Module):\n",
        "    def __init__(self, pretrained, num_ftrs, class_num):\n",
        "        super(ResNetForClassification, self).__init__()\n",
        "        self.pretrained = pretrained\n",
        "        self.pretrained.fc = nn.Linear(num_ftrs, class_num)\n",
        "        torch.nn.init.xavier_uniform_(self.pretrained.fc.weight)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained(x)\n",
        "        output = self.relu(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jungminki/Documents/Code/ML/notebooks/env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/jungminki/Documents/Code/ML/notebooks/env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Load the pre-trained ResNet-34 model\n",
        "resnet34_pretrained = models.resnet34(pretrained=True)\n",
        "num_ftrs = resnet34_pretrained.fc.in_features\n",
        "\n",
        "resnet34 = ResNetForClassification(resnet34_pretrained, num_ftrs, 72).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 th Batch\n",
            "1 th Batch\n",
            "2 th Batch\n",
            "3 th Batch\n",
            "4 th Batch\n",
            "5 th Batch\n",
            "6 th Batch\n",
            "7 th Batch\n"
          ]
        }
      ],
      "source": [
        "for int, (X, y) in enumerate(train_loader):\n",
        "    print(int, \"th Batch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total batches:  19\n",
            "0 th Batch\n",
            "0.033203125\n",
            "1 th Batch\n",
            "0.041015625\n",
            "2 th Batch\n",
            "0.03515625\n",
            "3 th Batch\n",
            "0.037109375\n",
            "4 th Batch\n",
            "0.044921875\n",
            "5 th Batch\n",
            "0.03515625\n",
            "6 th Batch\n",
            "0.037109375\n",
            "7 th Batch\n",
            "0.048828125\n",
            "Total time:  68.43477908299997\n",
            "Total acc 8\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "# from torch.profiler import profile, ProfilerActivity\n",
        "\n",
        "# with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
        "accuracies = []\n",
        "num_epochs = 1\n",
        "lr = 1e-5\n",
        "weight_decay = 5e-4\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "# params_1x = [param for name, param in resnet34.named_parameters() if 'fc' not in str(name)]\n",
        "\n",
        "# Freeze all layers\n",
        "for param in resnet34.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last layer (assuming it's named \"layerN\")\n",
        "for name, param in resnet34.named_parameters():\n",
        "    if \"fc\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(resnet34.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "start_t = timer()\n",
        "print(\"Total batches: \", len(train_loader))\n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "    for int, (X, y) in enumerate(train_loader):\n",
        "        print(int, \"th Batch\")\n",
        "        X = X.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_diagonal_array = torch.zeros([batch_size, 72], device=device)\n",
        "        for i in range(batch_size):\n",
        "            y_diagonal_array[i][y[i].item()] = 1\n",
        "\n",
        "        y_diagonal_array = y_diagonal_array.to(device)\n",
        "\n",
        "        resnet34.train()\n",
        "        res = resnet34(X)\n",
        "        accuracy = accuracy_top3(res, list(y))\n",
        "        accuracies.append(accuracy)\n",
        "        print(accuracy)\n",
        "        loss = loss_function(res, y_diagonal_array)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "end_t = timer()\n",
        "print(\"Total time: \", end_t - start_t)\n",
        "\n",
        "# print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))\n",
        "print(\"Total acc\", len(accuracies))\n",
        "plt.plot(accuracies)\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('Top-3 Accuracy')\n",
        "plt.title('Training Top-3 Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is something wrong with the model. I'll try the following adjustments.\n",
        "1. Try different learning rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Finding learning rate\n",
        "\n",
        "# import torch.optim as optim\n",
        "\n",
        "# initial_lr = 1e-7\n",
        "# final_lr = 1\n",
        "# step_size = len(train_loader)\n",
        "# def lr_lambda(epoch):\n",
        "#     mul = (final_lr / initial_lr) ** (epoch / step_size)\n",
        "#     return mul\n",
        "# optimizer = optim.SGD(cnn.parameters(), lr=initial_lr)\n",
        "# scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "# lr_find_loss = []\n",
        "# lr_find_lr = []\n",
        "\n",
        "# # Loop through each batch to get the loss and lr\n",
        "# for i, (inputs, labels) in enumerate(train_loader):\n",
        "#     target_in_array = torch.tensor([[1 if i == value else 0 for i in range(len(class_list))] for value in labels], dtype=torch.float32)\n",
        "\n",
        "#     optimizer.zero_grad()\n",
        "#     outputs = cnn(inputs)\n",
        "#     lossFunction = nn.MSELoss()\n",
        "#     loss = lossFunction(outputs, target_in_array)\n",
        "\n",
        "#     # Record this iteration's loss and learning rate\n",
        "#     lr_find_loss.append(loss.item())\n",
        "#     lr_find_lr.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "#     # Backward pass\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     # Step with the learning rate scheduler\n",
        "#     scheduler.step()\n",
        "\n",
        "# # Plot the learning rate range test results\n",
        "# plt.semilogx(lr_find_lr, lr_find_loss)\n",
        "# plt.xlabel(\"Learning Rate\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9qRMf3sE2g1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPFJI-NLE2g2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nkfWshqE2g2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il4_AxOEPJ9o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrdnorBaE2g2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Ta7I-1E2g2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-xUZn-bE2g1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
