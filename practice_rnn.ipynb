{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>rain</th>\n",
       "      <th>tmax_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01</th>\n",
       "      <td>60.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-02</th>\n",
       "      <td>52.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-03</th>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-04</th>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-05</th>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tmax  tmin  rain  tmax_tomorrow\n",
       "1970-01-01  60.0  35.0   0.0           52.0\n",
       "1970-01-02  52.0  39.0   0.0           52.0\n",
       "1970-01-03  52.0  35.0   0.0           53.0\n",
       "1970-01-04  53.0  36.0   0.0           52.0\n",
       "1970-01-05  52.0  35.0   0.0           50.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/clean_weather.csv\", index_col=0)\n",
    "data = data.ffill()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "class rnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight_input = np.random.rand(1, 5) / 5 - 0.1\n",
    "\n",
    "        self.weight_hidden = np.random.rand(5, 5) / 5 - 0.1\n",
    "        self.bias_hidden = np.random.rand(1, 5) / 5 - 0.1\n",
    "\n",
    "        self.weight_output = np.random.rand(5, 1) * 50\n",
    "        self.bias_output = np.random.rand(1, 1)\n",
    "        self.hidden_step = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_output = []\n",
    "        hiddens = np.zeros((10, 5))\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            # Reshapping input\n",
    "            x_input = x[i].reshape(1, 1)\n",
    "        \n",
    "            # Input Layer\n",
    "            x_input = x_input @ self.weight_input\n",
    "\n",
    "            # Hidden Layer\n",
    "            if i != 0:\n",
    "                x_hidden = np.tanh(x_input + (self.hidden_step @ self.weight_hidden))\n",
    "            else:\n",
    "                x_hidden = np.tanh(x_input)\n",
    "\n",
    "            # Output Layer\n",
    "            output = (x_hidden @ self.weight_output).item()\n",
    "\n",
    "            # Saving hidden states and output values\n",
    "            self.hidden_step = x_hidden\n",
    "            hiddens[i,:] = x_hidden\n",
    "            x_output.append(output)\n",
    "\n",
    "        return x_output, hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model_for_weather = rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ train ↓\u001b[0m\n",
      "[60. 52. 52. 53. 52. 50. 52. 56. 54. 57.]\n",
      "\u001b[95m↓ prediction ↓\u001b[0m\n",
      "[71.0742190277846, 73.91953306750138, 73.97074609609383, 74.50992244242337, 74.04836420420375, 72.93682904415054, 73.89303982479758, 75.98268476297383, 75.20618121079521, 76.5658351071108]\n",
      "\u001b[95m↓ hiddens ↓\u001b[0m\n",
      "[[ 0.52684078  0.98863364  0.84349363  0.49192612 -0.72406738]\n",
      " [ 0.4913896   0.97746488  0.80455755  0.58573775 -0.69308416]\n",
      " [ 0.49997043  0.9777974   0.80332419  0.58507687 -0.69762274]\n",
      " [ 0.50739162  0.9796219   0.81056156  0.59140405 -0.70547389]\n",
      " [ 0.50018991  0.97781757  0.8035146   0.58656475 -0.69779462]\n",
      " [ 0.48542095  0.97370097  0.78833187  0.5736915  -0.6817688 ]\n",
      " [ 0.50005263  0.977801    0.80314708  0.58349426 -0.69762897]\n",
      " [ 0.52871827  0.98422052  0.83068071  0.60857924 -0.72769806]\n",
      " [ 0.51487162  0.98130927  0.81792654  0.60100623 -0.71329606]\n",
      " [ 0.53618209  0.98552925  0.83714233  0.61631894 -0.73508814]]\n"
     ]
    }
   ],
   "source": [
    "train = data.head(10).tmax.values\n",
    "print(f\"\\033[95m↓ train ↓\\033[0m\\n{train}\")\n",
    "\n",
    "prediction, hiddens = rnn_model_for_weather(train)\n",
    "print(f\"\\033[95m↓ prediction ↓\\033[0m\\n{prediction}\")\n",
    "print(f\"\\033[95m↓ hiddens ↓\\033[0m\\n{hiddens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actual, predicted):\n",
    "    return np.mean((actual-predicted)**2)\n",
    "\n",
    "# The gradient of mse wrt the network outputs, which is the variable 'predicted'\n",
    "# It's actually -2/n * (actual-predicted), but we can drop the coefficient 2/n.\n",
    "def mse_grad(actual, predicted):\n",
    "    return (predicted - actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ loss ↓\u001b[0m\n",
      "[11.07421903 21.91953307 21.9707461  21.50992244 22.0483642  22.93682904\n",
      " 21.89303982 19.98268476 21.20618121 19.56583511]\n"
     ]
    }
   ],
   "source": [
    "loss_grad = mse_grad(train, prediction)\n",
    "print(f\"\\033[95m↓ loss ↓\\033[0m\\n{loss_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Gradient of the last sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10 input variables. To calculate the gradient of the parameters, we first need to determine the value of the final input variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ output_weight_grad ↓\u001b[0m\n",
      "[[ 10.49085036]\n",
      " [ 19.28270284]\n",
      " [ 16.37938883]\n",
      " [ 12.05879483]\n",
      " [-14.38261327]]\n"
     ]
    }
   ],
   "source": [
    "# Output_weight_grad\n",
    "# This is the gradient of loss wrt output weight\n",
    "# Output = X_hidden @ W_output + B_ouput\n",
    "# output_weight_grad = loss_grad @  (X_hidden @ W_output + B_output)/derivative wrt W_output =  loss_grad @ X_hidden\n",
    "# We have X_hiddens in the array 'hiddens'\n",
    "output_weight_grad = hiddens[9][:,np.newaxis] @ loss_grad[9].reshape(1,1)\n",
    "print(f\"\\033[95m↓ output_weight_grad ↓\\033[0m\\n{output_weight_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ output_bias_grad ↓\u001b[0m\n",
      "[[19.56583511]]\n"
     ]
    }
   ],
   "source": [
    "# This is the gradient of loss wrt output bias\n",
    "# Output bias gradient is just summation of all loss\n",
    "# Output = X_hidden @ W_output + B_ouput\n",
    "# Output bias gradient = loss_grad @ (X_hidden @ W_output + B_output)/derivative wrt B_output =  loss_grad @ 1\n",
    "output_bias_grad = loss_grad[9].reshape(1,1)\n",
    "print(f\"\\033[95m↓ output_bias_grad ↓\\033[0m\\n{output_bias_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ hidden_output_gradient ↓\u001b[0m\n",
      "[[604.2277146  598.80819903 603.54144274 923.26096434 667.01917725]]\n"
     ]
    }
   ],
   "source": [
    "# hidden_output_gradient\n",
    "# Output = X_hidden @ W_output + B_ouput\n",
    "# hidden_output_gradient = loss_grad @  (X_hidden @ W_output + B_output)/derivative wrt X_hidden =  loss_grad @ W_output\n",
    "hidden_output_gradient9 = loss_grad[9].reshape(1,1) @ rnn_model_for_weather.weight_output.T\n",
    "print(f\"\\033[95m↓ hidden_output_gradient ↓\\033[0m\\n{hidden_output_gradient9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ activation_grad ↓\u001b[0m\n",
      "[[0.71250877 0.02873209 0.29919272 0.62015096 0.45964543]]\n",
      "\u001b[95m↓ hidden_output_gradient ↓\u001b[0m\n",
      "[[430.51754363  17.20501289 180.57520357 572.5611729  306.59231761]]\n"
     ]
    }
   ],
   "source": [
    "# activation_grad\n",
    "\n",
    "activation_grad = 1 - hiddens[9][np.newaxis, :] ** 2\n",
    "print(f\"\\033[95m↓ activation_grad ↓\\033[0m\\n{activation_grad}\")\n",
    "hidden_output_gradient9 = np.multiply(hidden_output_gradient9, activation_grad)\n",
    "print(f\"\\033[95m↓ hidden_output_gradient ↓\\033[0m\\n{hidden_output_gradient9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ hidden_weight_gradient ↓\u001b[0m\n",
      "[[526.46690868]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_weight_gradient = hidden_output_gradient9 @ hiddens[9][:, np.newaxis]\n",
    "print(f\"\\033[95m↓ hidden_weight_gradient ↓\\033[0m\\n{hidden_weight_gradient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ hidden_bias_gradient ↓\u001b[0m\n",
      "301.4902501193734\n"
     ]
    }
   ],
   "source": [
    "hidden_bias_gradient = np.mean(hidden_output_gradient9)\n",
    "print(f\"\\033[95m↓ hidden_bias_gradient ↓\\033[0m\\n{hidden_bias_gradient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ input_weight_gradient ↓\u001b[0m\n",
      "[[24539.49998718   980.68573447 10292.78660353 32635.98685506\n",
      "  17475.76210378]]\n"
     ]
    }
   ],
   "source": [
    "input_weight_gradient = train[9].reshape(1,1) @ hidden_output_gradient9\n",
    "print(f\"\\033[95m↓ input_weight_gradient ↓\\033[0m\\n{input_weight_gradient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are going to calculate sequence 8's gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ loss8_grad ↓\u001b[0m\n",
      "[[21.20618121]]\n"
     ]
    }
   ],
   "source": [
    "loss8_grad = loss_grad[8].reshape(1,1)\n",
    "print(f\"\\033[95m↓ loss8_grad ↓\\033[0m\\n{loss8_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ loss8_grad.shape ↓\u001b[0m\n",
      "(1, 1)\n",
      "\u001b[95m↓ hiddens[8].reshape(-1, 1).shape ↓\u001b[0m\n",
      "(1, 5)\n",
      "\u001b[95m↓ output_weight_grad ↓\u001b[0m\n",
      "[[ 10.49085036]\n",
      " [ 19.28270284]\n",
      " [ 16.37938883]\n",
      " [ 12.05879483]\n",
      " [-14.38261327]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\033[95m↓ loss8_grad.shape ↓\\033[0m\\n{loss8_grad.shape}\")\n",
    "print(f\"\\033[95m↓ hiddens[8].reshape(-1, 1).shape ↓\\033[0m\\n{hiddens[8].reshape(-1, 1).T.shape}\")\n",
    "print(f\"\\033[95m↓ output_weight_grad ↓\\033[0m\\n{output_weight_grad}\")\n",
    "output_weight_grad += hiddens[8].reshape(-1, 1) @ loss8_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ output_bias_grad ↓\u001b[0m\n",
      "[[40.77201632]]\n"
     ]
    }
   ],
   "source": [
    "output_bias_grad += loss8_grad\n",
    "print(f\"\\033[95m↓ output_bias_grad ↓\\033[0m\\n{output_bias_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ hidden_output_gradient8 ↓\u001b[0m\n",
      "[[534.51897159  25.88984607 226.23379412 670.87851134 366.97666118]]\n"
     ]
    }
   ],
   "source": [
    "# Gradient rwt hidden output \n",
    "hidden_output_gradient8 = loss8_grad @ rnn_model_for_weather.weight_output.T\n",
    "\n",
    "# Add the previous hidden output gradient9\n",
    "# Multiply hidden_output_gradient9 by the weight to pull it back to the current sequence position\n",
    "hidden_output_gradient8 += hidden_output_gradient9 @ rnn_model_for_weather.weight_hidden.T\n",
    "\n",
    "tanh_derivative = 1 - hiddens[8].reshape(1,-5) **2\n",
    "hidden_output_gradient8 = np.multiply(tanh_derivative, hidden_output_gradient8)\n",
    "print(f\"\\033[95m↓ hidden_output_gradient8 ↓\\033[0m\\n{hidden_output_gradient8}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ hidden_weight_gradient ↓\u001b[0m\n",
      "[[526.46690868]]\n",
      "\u001b[95m↓ hidden_weight_gradient ↓\u001b[0m\n",
      "[[1153.56328621]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[95m↓ hidden_weight_gradient BEFORE↓\\033[0m\\n{hidden_weight_gradient}\")\n",
    "hidden_weight_gradient +=  hidden_output_gradient8 @ hiddens[8][:, np.newaxis] \n",
    "print(f\"\\033[95m↓ hidden_weight_gradient ↓\\033[0m\\n{hidden_weight_gradient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ hidden_bias_gradient.shape ↓\u001b[0m\n",
      "301.4902501193734\n",
      "\u001b[95m↓ hidden_bias_gradient.shape ↓\u001b[0m\n",
      "666.3898069787671\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[95m↓ hidden_bias_gradient.shape BEFORE↓\\033[0m\\n{hidden_bias_gradient}\")\n",
    "hidden_bias_gradient += np.mean(hidden_output_gradient8)\n",
    "print(f\"\\033[95m↓ hidden_bias_gradient.shape ↓\\033[0m\\n{hidden_bias_gradient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ input_weight_gradient ↓\u001b[0m\n",
      "[[53403.52445306  2378.73742202 22509.41148597 68863.42646755\n",
      "  37292.50180745]]\n"
     ]
    }
   ],
   "source": [
    "input_weight_gradient += train[8].reshape(1,1) @ hidden_output_gradient8\n",
    "print(f\"\\033[95m↓ input_weight_gradient ↓\\033[0m\\n{input_weight_gradient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final sequence gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step, there's no need to accumulate gradients for the hidden weights and biases across timesteps. It's because, in the final step, hidden state does not affect any previous hidden state, thus we don't need to add hidden_weight_grad and hidden_bias_grad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ loss0_grad ↓\u001b[0m\n",
      "[[11.07421903]]\n"
     ]
    }
   ],
   "source": [
    "loss0_grad = loss_grad[0].reshape(1,1)\n",
    "print(f\"\\033[95m↓ loss0_grad ↓\\033[0m\\n{loss0_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ output_weight_grad ↓\u001b[0m\n",
      "[[ 27.24366154]\n",
      " [ 51.04087046]\n",
      " [ 43.06552034]\n",
      " [ 30.25153944]\n",
      " [-37.52737952]]\n"
     ]
    }
   ],
   "source": [
    "output_weight_grad += hiddens[0].reshape(-1, 1) @ loss0_grad\n",
    "print(f\"\\033[95m↓ output_weight_grad ↓\\033[0m\\n{output_weight_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_bias_grad += np.mean(loss0_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m↓ hidden_output_gradient0 ↓\u001b[0m\n",
      "[[341.9915387  338.92410497 341.60311035 522.56364643 377.53136649]]\n"
     ]
    }
   ],
   "source": [
    "hidden_output_gradient0 = loss0_grad @ rnn_model_for_weather.weight_output.T\n",
    "print(f\"\\033[95m↓ hidden_output_gradient0 ↓\\033[0m\\n{hidden_output_gradient0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
